---
title: "Introduction: Adjusted Predictions and Marginal Effects for Random Effects Models"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction: Adjusted Predictions and Marginal Effects for Random Effects Models}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r set-options, echo=FALSE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  dev = "png",
  fig.width = 7,
  fig.height = 4,
  message = FALSE,
  warning = FALSE
)
options(width = 800)

pkgs <- c(
  "ggplot2",
  "lme4",
  "glmmTMB",
  "patchwork",
  "sjlabelled",
  "htmltools"
)

if (!all(vapply(pkgs, requireNamespace, quietly = TRUE, FUN.VALUE = logical(1L)))) {
  knitr::opts_chunk$set(eval = FALSE)
}
```

```{r echo=FALSE, message=FALSE}
library(htmltools)
callout_tip <- function(header = NULL, ...) {
  div(
    class = "callout-tip",
    tags$h1(
      tags$img(src = "../man/figures/summary.png", width = "20", height = "17", style = "vertical-align:middle"), # nolint
      header
    ),
    ...
  )
}
includeCSS("../man/figures/callout.css")
```

This vignette shows how to calculate adjusted predictions for mixed models. However, for mixed models, since random effects are involved, we can calculate _conditional predictions_ and _marginal predictions_. We also have to distinguish between _population-level_ and _unit-level_ predictions. Additionally, _random effects uncertainty_ can be taken into account, which would lead to _prediction intervals_ instead of _confidence intervals_.

But one thing at a time...

```{r echo=FALSE}
callout_tip(
  "Summary of most important points:",
  tags$ul(
    tags$li("Predictions can be made on the population-level or for each level of the grouping variable (unit-level). If unit-level predictions are requested, you need to set ", tags$code("type=\"random\""), " and specify the grouping variable(s) in the ", tags$code("terms"), " argument."), # nolint
    tags$li("Population-level predictions can be either conditional (predictions for a \"typical\" group) or marginal (average predictions across all groups). Set ", tags$code("margin=\"empirical\""), " for marginal predictions. You'll notice differences in predictions especially for unequal group sizes at the random effects level."), # nolint
    tags$li("For conditional predictions, you can either calculate confidence or prediction intervals. Prediction intervals can be obtained by setting ", tags$code("type=\"random\""), ". Marginal predictions (i.e. ", tags$code("margin=\"empirical\""), ") always return confidence intervals."), # nolint
    tags$li("To get confidence intervals for unit-level predictions, set ", tags$code("type=\"random\""), " and ", tags$code("interval=\"confidence\""), ".") # nolint
  )
)
```

## Population-level predictions for mixed effects models

Mixed models are used to account for the dependency of observations within groups, e.g. repeated measurements within subjects, or students within schools. The dependency is modeled by random effects, i.e. mixed model at least have one grouping variable (or factor) as higher level unit.

At the lowest level, you have your _fixed effects_, i.e. your "independent variables" or "predictors".

Adjusted predictions can now be calculated for specified values or levels of the focal terms, however, either for the full sample (population-level) or for each level of the grouping variable (unit-level). The latter is particularly useful when the grouping variable is of interest, e.g. when you want to compare the effect of a predictor between different groups.

### Conditional and marginal effects and predictions

We start with the population-level predictions. Here you can either calculate the _conditional_ or the _marginal_ effect. The conditional effect is the effect of a predictor in an average or typical group, while the marginal effect is the average effect of a predictor across all groups. E.g. let's say we have `countries` as grouping variable and `gdp` (gross domestic product per capita) as predictor, then the conditional and marginal effect would be:

- conditional effect: effect of `gdp` in an _average_ or _typical_ country. To get conditional predictions, we use `predict_response()` or `predict_response(margin = "mean_mode")`.

- marginal effect: average effect of `gdp` _across all_ countries. To get marginal (or average) predictions, we use `predict_response(margin = "empirical")`.

While the term "effect" referes to the strength of the relationship between a predictor and the response, "predictions" refer to the actual predicted values of the response. Thus, in the following, we will talk about conditional and marginal (or average) _predictions_.

In a balanced data set, where all groups have the same number of observations, the conditional and marginal predictions are often similar (maybe slightly different, depending on the non-focal predictors). However, in unbalanced data, the conditional and marginal predicted values can largely differ.

```{r}
library(ggeffects)
library(lme4)
data(sleepstudy)

# balanced data set
m <- lmer(Reaction ~ Days + (1 + Days | Subject), data = sleepstudy)

# conditional predictions
predict_response(m, "Days [1,5,9]")

# average marginal predictions
predict_response(m, "Days [1,5,9]", margin = "empirical")

# create imbalanced data set
set.seed(123)
strapped <- sleepstudy[sample.int(nrow(sleepstudy), nrow(sleepstudy), replace = TRUE), ]
m <- lmer(Reaction ~ Days + (1 + Days | Subject), data = strapped)

# conditional predictions
predict_response(m, "Days [1,5,9]")

# average marginal predictions
predict_response(m, "Days [1,5,9]", margin = "empirical")
```

### Prediction intervals (random effects uncertainty)

For conditional predictions (i.e. when `margin` is not set to `"empirical"`), the uncertainty of the random effects can be taken into account. This leads to _prediction intervals_ instead of _confidence intervals_. To do so, we need to set `type = "random"`.

The random-effect variance, which is included when `type = "random"`, is the _mean_ random-effect variance. Calculation is based on the proposal from _Johnson et al. 2014_, which is also implemented in functions like [`performance::r2()`](https://easystats.github.io/performance/reference/r2_nakagawa.html) or [`insight::get_variance()`](https://easystats.github.io/insight/reference/get_variance.html) to get r-squared values or random-effect variances for mixed models with more complex random effects structures.

As can be seen, compared to the previous examples, predicted values are identical (both on the population-level). However, standard errors, and thus the resulting confidence (or prediction) intervals are much larger .

```{r}
predict_response(m, "Days [1,5,9]", type = "random")

# Or as comparison via plots:
library(patchwork)
library(ggplot2)
pr1 <- predict_response(m, "Days [1,5,9]")
pr2 <- predict_response(m, "Days [1,5,9]", type = "random")
plot(pr1, limits = c(200, 400)) +
  ggtitle("Confidence Intervals") +
  plot(pr2, limits = c(200, 400)) +
  ggtitle("Prediction Intervals")
```

It is also possible to obtain predicted values by simulating from the model, where predictions are based on `simulate()`. The predicted values come closer to _marginal predictions_ estimates, but the intervals come closer to _prediction intervals_.

```{r}
predict_response(m, "Days", type = "simulate")
```

### When are predictions affected by `type = "fixed"` and `type = "random"`?

The conditional predictions returned by `predict_response()` for the default marginalization (i.e. when `margin` is set to `"mean_reference"` or `"mean_mode"`) may differ, depending on whether `type = "fixed"` or `type = "random"` is used. This is because `predict(..., re.form = NA)` is called for `type = "fixed"`, and `predict(..., re.form = NULL)` is called for `type = "random"`, which can lead to different predictions depending on whether `REML` was set to `TRUE` or `FALSE` for model fitting.

When `REML = FALSE`, `re.form = NA` and `re.form = NULL` are identical, and thus predictions are not affected by `type = "fixed"` and `type = "random"`. However, when `REML = TRUE`, `re.form = NA` and `re.form = NULL` can return different predictions, also depending on whether factors are included in the model or not. The following example shows a case where predictions are affected by `type = "fixed"` and `type = "random"`.

```{r}
library(glmmTMB)
set.seed(123)
sleepstudy$x <- as.factor(sample(1:3, nrow(sleepstudy), replace = TRUE))
# REML is FALSE
m1 <- glmmTMB(Reaction ~ Days + x + (1 + Days | Subject), data = sleepstudy, REML = FALSE)
# REML is TRUE
m2 <- glmmTMB(Reaction ~ Days + x + (1 + Days | Subject), data = sleepstudy, REML = TRUE)

# predictions when REML is FALSE - no difference between type = "fixed"
# and type = "random" in predictions, only for intervals
predict_response(m1, "Days [1:3]")
predict_response(m1, "Days [1:3]", type = "random")

# predictions when REML is TRUE - we now see a difference both
# for intervals *and* predictions
predict_response(m2, "Days [1:3]")
predict_response(m2, "Days[1:3]", type = "random")
```

### To summarize...

For conditional predictions (i.e. the default marginalization method in `predict_response()`), following differences can be observed:

- `type = "fixed"`: predictions are on the population-level, and do not account for the random effect variances. `re.form = NA` when calling `predict()`. Intervals for the predicted values are _confidence intervals_.

- `type = "random"`: predictions are on the population-level, but conditioned on the random effects (i.e. including random effect variances). `re.form = NULL` when calling `predict()`. Intervals are _prediction intervals_.

- `type = "random", interval = "confidence"`: predictions are on the population-level, conditioned on the random effects (which means that `re.form = NULL` when calling `predict()`), however, intervals are _confidence intervals_.

## Population-level predictions for zero-inflated mixed models

For zero-inflated mixed effects models, typically fitted with the **glmmTMB** or **GLMMadaptive** packages, `predict_response()` can return predicted values of the response, conditioned on following prediction-types:

  * the fixed effects of the conditional (or "count") model only (`type = "fixed"`)
  * the fixed effects of the conditional model only (population-level), taking the random-effect variances into account, i.e. prediction intervals are returned (`type = "random"`)
  * the fixed effects and zero-inflation component (`type = "zero_inflated"`)
  * the fixed effects and zero-inflation component (population-level), taking the random-effect variances into account, i.e. prediction intervals are returned (`type = "zi_random"`)
  * the zero-inflation probabilities (`type = "zi_prob"`)
  * all model parameters (`type = "simulate"`)

 For `predict_response(margin = "empirical")`, `type = "simulate"` and `type = "random"` are not available. However, valid values for `type` can also be those based on the model's `predict()` method. For models of class `glmmTMB`, these are `"response"`, `"link"`, `"conditional"`, `"zprob"`, `"zlink"`, or `"disp"`.

### Adjusted predictions for the conditional model

For now, we show examples for conditional predictions, which is the default marginalization method in `predict_response()`.

```{r}
library(glmmTMB)
data(Salamanders)
m <- glmmTMB(
  count ~ spp + mined + (1 | site),
  ziformula = ~ spp + mined,
  family = truncated_poisson,
  data = Salamanders
)
```

Similar to mixed models without zero-inflation component, `type = "fixed"` and `type = "random"` for **glmmTMB**-models (with zero-inflation) both return predictions on the population-level, where the latter option accounts for the uncertainty of the random effects. For both, `predict(..., type = "link")` is called (however, predicted values are back-transformed to the response scale), and for the latter, prediction intervals are returned.

```{r}
predict_response(m, "spp")

predict_response(m, "spp", type = "random")
```

### Adjusted predictions for the full model

For `type = "zero_inflated"`, the predicted response value is the expected value `mu*(1-p)`. Since the zero inflation and the conditional model are working in "opposite directions", a higher expected value for the zero inflation means a lower response, but a higher value for the conditional ("count") model means a higher response. While it is possible to calculate predicted values with `predict(..., type = "response")`, standard errors and confidence intervals can not be derived directly from the `predict()`-function. Thus, confidence intervals for `type = "zero_inflated"` are based on quantiles of simulated draws from a multivariate normal distribution (see also _Brooks et al. 2017, pp.391-392_ for details).

```{r}
predict_response(m, "spp", type = "zero_inflated")
```

### Simulated outcome (full model)

In the above example, we get the conditional, not the marginal predictions (for example, not averaged over random effects groups). Furthermore, predictions are conditioned on `mined` when it is set to `"no"`. Therefore, it is possible to obtain predicted values by simulating from the model, where predictions are based on `simulate()` (see _Brooks et al. 2017, pp.392-393_ for details). This will return expected values of the response, averaged across all random effects groups and non-focal terms. To achieve this, use `type = "simulate"`. Note that intervals of this type will be wider than those of `type = "zero_inflated"`, because they account for the full uncertainty of model parameters.

```{r}
predict_response(m, "spp", type = "simulate")
```

### Average marginal predictions for the full model

In a similar fashion, you can obtain average marginal predictions for zero-inflated mixed models with `margin = "empirical"`. The returned values are most comparable to `predict_response(type = "simulate")`, because `margin = "empirical"` also returns expected values of the response, averaged across all random effects groups and all non-focal terms. The next example shows the average marginal predicted values of `spp` on the response across all `site`s, taking the zero-inflation component into account (i.e. `type = "zero_inflated"`).

```{r}
predict_response(m, "spp", type = "zero_inflated", margin = "empirical")
```

## Bias-correction for non-Gaussian models

For non-Gaussian models, predicted values are back-transformed to the response scale. However, back-transforming the population-level predictions (in _mixed_ models, when `type = "fixed"`) ignores the effect of the variation around the population mean, so the result on the original data scale is biased due to _Jensen's inequality_. In this case, it can be appropriate to apply a bias-correction. This is done by setting `bias_correction = TRUE`. By default, [`insight::get_variance_residual()`](https://easystats.github.io/insight/reference/get_variance_residual.html) is used to extract the residual variance, which is used to calculate the amount of correction. Optionally, you can provide your own estimates of uncertainty, e.g. based on [`insight::get_variance_random()`](https://easystats.github.io/insight/reference/get_variance_random.html), using the `sigma` argument.

Bias-correction comes closer to the expected values of the response, averaged across all random effects groups and all non-focal terms. The following example shows the bias-corrected predicted values of `spp`, which are closer to the simulated values than the non-bias-corrected ones.

```{r}
# no bias-correction
predict_response(m, "spp")

# bias-correction
predict_response(m, "spp", bias_correction = TRUE)

# closer to "simulate" for some of the predicted values
predict_response(m, "spp", type = "simulate")
```

## Unit-level predictions (predictions for each level of random effects)

Adjusted predictions can also be calculated for each group level (unit-level) in mixed models. Simply add the name of the related random effects term to the `terms`-argument, and set `type = "random"`. For `predict_response(margin = "empirical")`, you don't need to set `type = "random"`.

In the following example, we fit a linear mixed model and first simply plot the adjusted predictions, _not_ conditioned on random-effect variances.

```{r}
library(sjlabelled)
data(efc)
efc$e15relat <- as_label(efc$e15relat)
m <- lmer(neg_c_7 ~ c12hour + c160age + c161sex + (1 | e15relat), data = efc)
me <- predict_response(m, terms = "c12hour")
plot(me)
```

Changing the type to `type = "random"` still returns population-level predictions by default. Recall that the major difference between `type = "fixed"` and `type = "random"` is the uncertainty in the variance parameters. This leads to larger confidence intervals (i.e. prediction intervals) for adjusted predictions with `type = "random"`.

```{r}
me <- predict_response(m, terms = "c12hour", type = "random")
plot(me)
```

To compute adjusted predictions for each grouping level, add the related random term to the `terms`-argument. In this case, prediction intervals are calculated and predictions are conditioned on each unit-level of the random effects.

```{r}
me <- predict_response(m, terms = c("c12hour", "e15relat"), type = "random")
plot(me, show_ci = FALSE)
```

Since average marginal predictions already consider random effects by averaging over the groups, the `type`-argument is not needed when `margin = "empirical"` is set.

```{r}
me <- predict_response(m, terms = c("c12hour", "e15relat"), margin = "empirical")
plot(me, show_ci = FALSE)
```

Adjusted predictions, conditioned on random effects, can also be calculated for specific unit-levels only. Add the related values into brackets after the variable name in the `terms`-argument.

```{r}
me <- predict_response(m, terms = c("c12hour", "e15relat [child,sibling]"), type = "random")
plot(me, show_ci = FALSE)
```

...and including prediction intervals...

```{r}
plot(me)
```

The most complex plot in this scenario would be a term (`c12hour`) at certain values of two other terms (`c161sex`, `c160age`) for specific unit-levels of random effects (`e15relat`), so we have four variables in the `terms`-argument.

```{r fig.height=7}
me <- predict_response(
  m,
  terms = c("c12hour", "c161sex", "c160age", "e15relat [child,sibling]"),
  type = "random"
)
plot(me, n_rows = 2)
```

If the group factor has too many levels, you can also take a random sample of all possible levels and plot the adjusted predictions for this subsample of unit-levels. To do this, use `term = "<groupfactor> [sample=n]"`.

```{r}
set.seed(123)
m <- lmer(Reaction ~ Days + (1 + Days | Subject), data = sleepstudy)
me <- predict_response(m, terms = c("Days", "Subject [sample=7]"), type = "random")
plot(me)
```

You can also add the observed data points for each group using `show_data = TRUE`.

```{r}
plot(me, show_data = TRUE, show_ci = FALSE)
```

### Prediction and confidence intervals

If unit-levels are of interest, setting `type = "random"` is obligatory, unless you use `predict_response(margin = "empirical")`. However, sometimes it can be useful to have _confidence_ instead of prediction intervals, e.g. for [pairwise comparisons](introduction_comparisons_1) of random effects. Confidence instead of prediction intervals can be calculated by explicitly setting `interval = "confidence"`, in which case the random effects variances are ignored. `predict_response(margin = "empirical")` always returns confidence intervals.

```{r}
me <- predict_response(
  m,
  terms = c("Days", "Subject [sample=7]"),
  type = "random",
  interval = "confidence"
)
# for average marginal effects, this would be:
# predict_response(m, terms = c("Days", "Subject [sample=7]"), margin = "empirical")
plot(me)
```

## Population-level predictions for `gam` and `glmer` models

The output of `predict_response()` indicates that the grouping variable of the random effects is set to "population level" (adjustment), e.g. in case of *lme4*, following is printed:

> Adjusted for:
> * Subject = 0 (population-level)

A comparable model fitted with `mgcv::gam()` would print a different message:

> Adjusted for:
> * Subject = 308

The reason is because the correctly printed information about adjustment for random effects is based on `insight::find_random()`, which returns `NULL` for `gam`s with random effects defined via `s(..., bs = "re")`. However, predictions are still correct, when population-level predictions are requested. Here's an example:

```{r message = FALSE}
data("sleepstudy", package = "lme4")
# mixed model with lme4
m_lmer <- lme4::lmer(Reaction ~ poly(Days, 2) + (1 | Subject),
  data = sleepstudy
)
# equivalent model, random effects are defined via s(..., bs = "re")
m_gam <- mgcv::gam(Reaction ~ poly(Days, 2) + s(Subject, bs = "re"),
  family = gaussian(), data = sleepstudy, method = "ML"
)

# predictions are identical
predict_response(m_gam, terms = "Days", exclude = "s(Subject)", newdata.guaranteed = TRUE)

predict_response(m_lmer, terms = "Days")
```

# References

Brooks ME, Kristensen K, Benthem KJ van, Magnusson A, Berg CW, Nielsen A, et al. glmmTMB Balances Speed and Flexibility Among Packages for Zero-inflated Generalized Linear Mixed Modeling. The R Journal. 2017;9: 378â€“400.

Johnson PC. 2014. Extension of Nakagawa & Schielzeth's R2GLMM to random slopes models. Methods Ecol Evol, 5: 944-946. (doi: 10.1111/2041-210X.12225)
