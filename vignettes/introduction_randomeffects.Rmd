---
title: "Introduction: Adjusted Predictions and Marginal Effects for Random Effects Models"
author: "Daniel LÃ¼decke"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction: Adjusted Predictions and Marginal Effects for Random Effects Models}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r set-options, echo=FALSE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>", dev = "png", fig.width = 7, fig.height = 4, message = FALSE, warning = FALSE)
options(width = 800)
if (!requireNamespace("ggplot2", quietly = TRUE) ||
    !requireNamespace("lme4", quietly = TRUE) ||
    !requireNamespace("glmmTMB", quietly = TRUE) ||
    !requireNamespace("patchwork", quietly = TRUE) ||
    !requireNamespace("sjlabelled", quietly = TRUE)) {
  knitr::opts_chunk$set(eval = FALSE)
}
```

This vignette shows how to calculate adjusted predictions for mixed models. However, for mixed models, since random effects are involved, we can calculate _conditional effects_ and _marginal effects_. We also have to distinguish between _population-level_ and _unit-level_ predictions. Additionally, _random effects uncertainty_ can be taken into account, which would lead to _prediction intervals_ instead of _confidence intervals_.

But one thing at a time...

## Population-level predictions for mixed effects models

Mixed models are used to account for the dependency of observations within groups, e.g. repeated measurements within subjects, or students within schools. The dependency is modeled by random effects, i.e. mixed model at least have one grouping variable (or factor) as higher level unit.

At the lowest level, you have your _fixed effects_, i.e. your "independent variables" or "predictors".

Adjusted predictions can now be calculated for specified values or levels of the focal terms, however, either for the full sample (population-level) or for each level of the grouping variable (unit-level). The latter is particularly useful when the grouping variable is of interest, e.g. when you want to compare the effect of a predictor between different groups.

### Conditional and marginal effects

We start with the population-level predictions. Here you can either calculate the _conditional_ or the _marginal_ effect. The conditional effect is the effect of a predictor in an average or typical group, while the marginal effect is the average effect of a predictor across all groups. E.g. let's say we have `countries` as grouping variable and `gdp` (gross domestic product per capita) as predictor, then the conditional and marginal effect would be:

- conditional effect: effect of `gdp` in an _average_ or _typical_ country (using `predict_response()` or `predict_response(margin = "mean_mode")`)

- marginal effect: average effect of `gdp` _across all_ countries (using `predict_response(margin = "empirical")`)

In a balanced data set, where all groups have the same number of observations, the conditional and marginal effect are often similar (maybe slightly different, depending on the non-focal predictors). However, in unbalanced data, the conditional and marginal effect can largely differ.

```{r}
library(ggeffects)
library(lme4)
data(sleepstudy)

# balanced data set
m <- lmer(Reaction ~ Days + (1 + Days | Subject), data = sleepstudy)

# conditional effect
predict_response(m, "Days [1,5,9]")

# average marginal effect
predict_response(m, "Days [1,5,9]", margin = "empirical")

# create imbalanced data set
set.seed(123)
strapped <- sleepstudy[sample.int(nrow(sleepstudy), nrow(sleepstudy), replace = TRUE), ]
m <- lmer(Reaction ~ Days + (1 + Days | Subject), data = strapped)

# conditional effect
predict_response(m, "Days [1,5,9]")

# average marginal effect
predict_response(m, "Days [1,5,9]", margin = "empirical")
```

### Prediction intervals (random effects uncertainty)

For conditional effects (i.e. when `margin` is not set to `"empirical"`), the uncertainty of the random effects can be taken into account. This leads to _prediction intervals_ instead of _confidence intervals_. To do so, we need to set `type = "random"`.

The random-effect variance, which is included when `type = "random"`, is the _mean_ random-effect variance. Calculation is based on the proposal from _Johnson et al. 2014_, which is also implemented in functions like [`performance::r2()`](https://easystats.github.io/performance/reference/r2_nakagawa.html) or [`insight::get_variance()`](https://easystats.github.io/insight/reference/get_variance.html) to get r-squared values or random-effect variances for mixed models with more complex random effects structures.

As can be seen, compared to the previous examples, predicted values are identical (both on the population-level). However, standard errors, and thus the resulting confidence (or prediction) intervals are much larger .

```{r}
predict_response(m, "Days [1,5,9]", type = "random")

# Or as comparison via plots:
library(patchwork)
pr1 <- predict_response(m, "Days [1,5,9]")
pr2 <- predict_response(m, "Days [1,5,9]", type = "random")
plot(pr1, limits = c(200, 400)) + plot(pr2, limits = c(200, 400))
```

It is also possible to obtain predicted values by simulating from the model, where predictions are based on `simulate()`. The predicted values come closer to _marginal effects_ estimates, but the intervals come closer to _prediction intervals_.
 
```{r}
predict_response(m, "Days", type = "simulate")
```

### When are predictions affected by `type = "fixed"` and `type = "random"`?

The conditional effects (predicted values) returned by `predict_response()` for the default marginalization (i.e. when `margina` is set to `"mean_reference"` or `"mean_mode"`, which internally just calls `ggpredict()`) may differ, depending on whether `type = "fixed"` or `type = "random"` is used. This is because `predict(..., re.form = NA)` is called for `type = "fixed"`, and `predict(..., re.form = NULL)` is called for `type = "random"`, which can lead to different predictions depending on whether `REML` was set to `TRUE` or `FALSE` for model fitting.

When `REML = FALSE`, `re.form = NA` and `re.form = NULL` are identical, and thus predictions are not affected by `type = "fixed"` and `type = "random"`. However, when `REML = TRUE`, `re.form = NA` and `re.form = NULL` can return different predictions, also depending on whether factors are included in the model or not. The following example shows a case where predictions are affected by `type = "fixed"` and `type = "random"`.

```{r}
library(glmmTMB)
set.seed(123)
sleepstudy$x <- as.factor(sample(1:3, nrow(sleepstudy), replace = TRUE))
# REML is FALSE
m1 <- glmmTMB(Reaction ~ Days + x + (1 + Days | Subject), data = sleepstudy, REML = FALSE)
# REML is TRUE
m2 <- glmmTMB(Reaction ~ Days + x + (1 + Days | Subject), data = sleepstudy, REML = TRUE)

# predictions when REML is FALSE - no difference between type = "fixed"
# and type = "random" in predictions, only for intervals
predict_response(m1, "Days [1:3]")
predict_response(m1, "Days [1:3]", type = "random")

# predictions when REML is TRUE - we now see a difference both
# for intervals *and* predictions
predict_response(m2, "Days [1:3]")
predict_response(m2, "Days[1:3]", type = "random")
```

### To summarize...

For conditional effects (i.e. the default marginalization method in `predict_response()`), following differences can be observed:

- `type = "fixed"`: predictions are on the population-level, and do not account for the random effect variances. `re.form = NA` when calling `predict()`. Intervals for the predicted values are _confidence intervals_.

- `type = "random"`: predictions are on the population-level, but conditioned on the random effects (i.e. including random effect variances). `re.form = NULL` when calling `predict()`. Intervals are _prediction intervals_.

- `type = "random", interval = "confidence"`: predictions are on the population-level, conditioned on the random effects (which means that `re.form = NULL` when calling `predict()`), however, intervals are _confidence intervals_.

## Population-level predictions for `gam` and `glmer` models

The output of `ggpredict()` indicates that the grouping variable of the random effects is set to "population level" (adjustment), e.g. in case of *lme4*, following is printed:

> Adjusted for:
> * Subject = 0 (population-level)

A comparable model fitted with `mgcv::gam()` would print a different message:

> Adjusted for:
> * Subject = 308

The reason is because the correctly printed information about adjustment for random effects is based on `insight::find_random()`, which returns `NULL` for `gam`s with random effects defined via `s(..., bs = "re")`. However, predictions are still correct, when population-level predictions are requested. Here's an example:

```{r message = FALSE}
data("sleepstudy", package = "lme4")
# mixed model with lme4
m_lmer <- lme4::lmer(Reaction ~ poly(Days, 2) + (1 | Subject),
  data = sleepstudy
)
# equivalent model, random effects are defined via s(..., bs = "re")
m_gam <- mgcv::gam(Reaction ~ poly(Days, 2) + s(Subject, bs = "re"),
  family = gaussian(), data = sleepstudy, method = "ML"
)

# predictions are identical
predict_response(m_gam, terms = "Days", exclude = "s(Subject)", newdata.guaranteed = TRUE)

predict_response(m_lmer, terms = "Days")
```

## Adjusted predictions for zero-inflated mixed models

For zero-inflated mixed effects models, typically fitted with the **glmmTMB** or **GLMMadaptive** packages, `predict_response()` (except when `margin = "empirical"`) can return predicted values of the response, conditioned on following prediction-types:

  * the fixed effects of the conditional model only (`type = "fixed"`)
  * the fixed effects of the conditional model only (population-level), taking the random-effect variances into account, i.e. prediction intervals are returned (`type = "random"`)
  * the fixed effects and zero-inflation component (`type = "zero_inflated"`)
  * the fixed effects and zero-inflation component (population-level), taking the random-effect variances into account, i.e. prediction intervals are returned (`type = "zi_random"`)
  * all model parameters (`type = "simulate"`)

`predict_response(margin = "empirical")` accepts values for `type` based on the model's `predict()` method. For models of class `glmmTMB`, these are `"response"`, `"link"`, `"conditional"`, `"zprob"`, `"zlink"`, or `"disp"`. By default, `type = "response"`, and the returned average marginal effects (averaged across all random effects and model components) are most comparable to `predict_response(type = "simulate")`

### Adjusted predictions for the conditional model

For now, we show examples for conditional effects, which are the default marginalization method in `predict_response()`.

```{r}
library(glmmTMB)
data(Salamanders)
m <- glmmTMB(
  count ~ spp + mined + (1 | site),
  ziformula = ~ spp + mined,
  family = truncated_poisson,
  data = Salamanders
)
```

Similar to mixed models without zero-inflation component, `type = "fixed"` and `type = "random"` for **glmmTMB**-models (with zero-inflation) both return predictions on the population-level, where the latter option accounts for the uncertainty of the random effects. For both, `predict(..., type = "link")` is called (however, predicted values are back-transformed to the response scale), and for the latter, prediction intervals are returned.

```{r}
predict_response(m, "spp")

predict_response(m, "spp", type = "random")
```

### Adjusted predictions for the full model

For `type = "zero_inflated"`, the predicted response value is the expected value `mu*(1-p)`. Since the zero inflation and the conditional model are working in "opposite directions", a higher expected value for the zero inflation means a lower response, but a higher value for the conditional model means a higher response. While it is possible to calculate predicted values with `predict(..., type = "response")`, standard errors and confidence intervals can not be derived directly from the `predict()`-function. Thus, confidence intervals for `type = "zero_inflated"` are based on quantiles of simulated draws from a multivariate normal distribution (see also _Brooks et al. 2017, pp.391-392_ for details).

```{r}
predict_response(m, "spp", type = "zero_inflated")
```

### Simulated outcome (full model)

It is possible to obtain predicted values by simulating from the model, where predictions are based on `simulate()` (see _Brooks et al. 2017, pp.392-393_ for details). To achieve this, use `type = "simulate"`.
 
```{r}
predict_response(m, "spp", type = "simulate")
```

### Average marginal effects for the full model

Average marginal effects for zero-inflated mixed models can be calculated with `margin = "empirical"`. The returned values are most comparable to `predict_response(type = "simulate")`. The next example shows the average marginal effect of `spp` on the response across all `site`s, taking the zero-inflation component into account.

```{r}
predict_response(m, "spp", margin = "empirical")
```

## Unit-level predictions (predictions for each level of random effects)

Adjusted predictions can also be calculated for each group level (unit-level) in mixed models. Simply add the name of the related random effects term to the `terms`-argument, and set `type = "random"`. For `predict_response(margin = "empirical")`, you don't need to set `type = "random"`.

In the following example, we fit a linear mixed model and first simply plot the adjusted predictions, _not_ conditioned on random-effect variances.

```{r}
library(sjlabelled)
data(efc)
efc$e15relat <- as_label(efc$e15relat)
m <- lmer(neg_c_7 ~ c12hour + c160age + c161sex + (1 | e15relat), data = efc)
me <- predict_response(m, terms = "c12hour")
plot(me)
```

Changing the type to `type = "random"` still returns population-level predictions by default. Recall that the major difference between `type = "fixed"` and `type = "random"` is the uncertainty in the variance parameters. This leads to larger confidence intervals (i.e. prediction intervals) for adjusted predictions with `type = "random"`.

```{r}
me <- predict_response(m, terms = "c12hour", type = "random")
plot(me)
```

To compute adjusted predictions for each grouping level, add the related random term to the `terms`-argument. In this case, prediction intervals are calculated and predictions are conditioned on each unit-level of the random effects.

```{r}
me <- predict_response(m, terms = c("c12hour", "e15relat"), type = "random")
plot(me, show_ci = FALSE)
```

Since average marginal effects already consider random effects by averaging over the groups, the `type`-argument is not needed when `margin = "empirical"` is set.

```{r}
me <- predict_response(m, terms = c("c12hour", "e15relat"), margin = "empirical")
plot(me, show_ci = FALSE)
```

Adjusted predictions, conditioned on random effects, can also be calculated for specific unit-levels only. Add the related values into brackets after the variable name in the `terms`-argument.

```{r}
me <- predict_response(m, terms = c("c12hour", "e15relat [child,sibling]"), type = "random")
plot(me, show_ci = FALSE)
```

...and including prediction intervals...

```{r}
plot(me)
```

The most complex plot in this scenario would be a term (`c12hour`) at certain values of two other terms (`c161sex`, `c160age`) for specific unit-levels of random effects (`e15relat`), so we have four variables in the `terms`-argument.

```{r fig.height=6}
me <- predict_response(
  m,
  terms = c("c12hour", "c161sex", "c160age", "e15relat [child,sibling]"),
  type = "random"
)
plot(me)
```

If the group factor has too many levels, you can also take a random sample of all possible levels and plot the adjusted predictions for this subsample of unit-levels. To do this, use `term = "<groupfactor> [sample=n]"`.

```{r}
set.seed(123)
m <- lmer(Reaction ~ Days + (1 + Days | Subject), data = sleepstudy)
me <- predict_response(m, terms = c("Days", "Subject [sample=7]"), type = "random")
plot(me)
```

You can also add the observed data points for each group using `show_data = TRUE`.

```{r}
plot(me, show_data = TRUE, show_ci = FALSE)
```

### Prediction and confidence intervals

If unit-levels are of interest, setting `type = "random"` is obligatory, unless you use `predict_response(margin = "empirical")`. However, sometimes it can be useful to have _confidence_ instead of prediction intervals, e.g. for [pairwise comparisons](introduction_comparisons_1) of random effects. Confidence instead of prediction intervals can be calculated by explicitly setting `interval = "confidence"`, in which case the random effects variances are ignored. `predict_response(margin = "empirical")` always returns confidence intervals.

```{r}
me <- predict_response(
  m,
  terms = c("Days", "Subject [sample=7]"),
  type = "random",
  interval = "confidence"
)
# for average marginal effects, this would be:
# predict_response(m, terms = c("Days", "Subject [sample=7]"), margin = "empirical")
plot(me)
```

# References

Brooks ME, Kristensen K, Benthem KJ van, Magnusson A, Berg CW, Nielsen A, et al. glmmTMB Balances Speed and Flexibility Among Packages for Zero-inflated Generalized Linear Mixed Modeling. The R Journal. 2017;9: 378â400.

Johnson PC, O'Hara RB. 2014. Extension of Nakagawa & Schielzeth's R2GLMM to random slopes models. Methods Ecol Evol, 5: 944-946. (doi: 10.1111/2041-210X.12225)
